# Self-Hosted AI Stack

A practical series on building AI infrastructure that runs entirely on your machine. No cloud dependencies, no API costs, full control.

## The Series

| Part | Description | What You'll Build |
|------|-------------|-------------------|
| [Part 1](part-1-building-the-foundation) | Building the Foundation | Open WebUI + PostgreSQL + pgAdmin |
| [Part 2](part-2-rag-with-tika-and-qdrant) | RAG with Tika & Qdrant | Document processing + vector search |
| [Part 3](part-3-receipt-processing-with-vlm) | Receipt Processing with VLM | AI-powered receipt/invoice extraction |

## Prerequisites

- **Docker & Docker Compose**
- **Ollama** - [ollama.com/download](https://ollama.com/download)
- 16GB RAM minimum (24GB+ recommended for VLM)

## Quick Start

Each part is self-contained. Pick any part and follow its README:

```bash
cd part-1-building-the-foundation
# or
cd part-2-rag-with-tika-and-qdrant
# or
cd part-3-receipt-processing-with-vlm
```

## Blog Series

This repo accompanies the **Complete Self-Hosted AI Infrastructure** blog series. Each part includes detailed explanations, architecture decisions, and lessons learned.

## License

MIT
